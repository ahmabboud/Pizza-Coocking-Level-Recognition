{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pizza_Doneness_Logic_Real_Time_Continuous_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmabboud/Pizza-Coocking-Level-Recognition/blob/main/Pizza_Doneness_Logic_Real_Time_Continuous_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1OZAYdCMaw8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "612e8864-db98-4237-a316-d30f4587544f"
      },
      "source": [
        "!pip install hmmlearn\n",
        "#!pip install --upgrade opencv-python\n",
        "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hmmlearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/7b/33f629a443a0671161c019e55c3f1b511c7e9fdce5ab8c8c3c33470eb939/hmmlearn-0.2.3-cp36-cp36m-manylinux1_x86_64.whl (363kB)\n",
            "\r\u001b[K     |█                               | 10kB 18.4MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 2.6MB/s eta 0:00:01\r\u001b[K     |██▊                             | 30kB 3.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 40kB 3.4MB/s eta 0:00:01\r\u001b[K     |████▌                           | 51kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 61kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 71kB 3.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 81kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 92kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 102kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 112kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 122kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 133kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 143kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 153kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 163kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 174kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 184kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 194kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 204kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 215kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 225kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 235kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 245kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 256kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 266kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 276kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 286kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 296kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 307kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 317kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 327kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 337kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 348kB 4.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 358kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 368kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.15 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->hmmlearn) (0.16.0)\n",
            "Installing collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.2.3\n",
            "\u001b[K     |████████████████████████████████| 49.4MB 81kB/s \n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgFTXx55JE7f"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBc_Z6LRYvL7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "51869a7a-ef84-4882-da4f-fd3e929f78b4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvVxNb-4rBqq"
      },
      "source": [
        "import fastai\n",
        "from fastai import *\n",
        "from fastai.vision import *\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import json\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "from hmmlearn import hmm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXMr3l_f7stH"
      },
      "source": [
        "#Define required paths for images and model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGRAcv6sn7nJ"
      },
      "source": [
        "root_path = Path('/content/gdrive/My Drive/Pizza/')\n",
        "project_path = Path(root_path/'oven-camera-validation/')\n",
        "image_path = Path(root_path/'oven-camera-validation/')\n",
        "model_path = Path(root_path/'models/')\n",
        "image_path_sample = Path(image_path/'D828C929CA75/c1e587aa-580e-4485-905c-4ca611b42493/')\n",
        "#image_path_sample = Path(image_path/'D828C929E2E9/75b4dc01-7e66-47eb-95dd-6b4435ca9df3/')\n",
        "#image_path_sample = Path(image_path/'D828C929E2F9/962ffbd5-cb2e-4b0c-8e69-a22262250b24/')\n",
        "#image_path_sample = Path(image_path/'D828C936B06D/0be853f9-a169-461d-b9c0-0e032bc78aa5/')\n",
        "#image_path_sample = Path(image_path/'D828C933D251/ef5e733c-7d7c-42b4-9901-ffac4dcdbfdb/')\n",
        "#image_path_sample = Path(image_path/'D828C929E2FC/3ed6c52f-cc12-43ab-884f-82d75c8eb39a/')\n",
        "#image_path_sample = Path(image_path/'D828C933D251/ef5e733c-7d7c-42b4-9901-ffac4dcdbfdb/')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuQoFS8B8X-V"
      },
      "source": [
        "##Here we read image files from the image folder along with their corespondeing meta data, sort them based on their time stamp, and store their filename along with the corresponding time stamp in a dictionary called 'sorted_images_dict'. \n",
        "\n",
        "* In practice, we will have a real time camera feed instead of a folder of images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdG5vazYNt2C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "6e7f5433-66b8-495c-dab3-a810803b9962"
      },
      "source": [
        "result_dict = {}\n",
        "for file_name in os.listdir(image_path_sample):\n",
        "    if file_name.endswith('.json'):\n",
        "        full_path_to_file = os.path.join(image_path_sample,file_name)\n",
        "        with open(full_path_to_file) as f:\n",
        "            meta_data_dict = json.load(f)\n",
        "            cooking_date = int(meta_data_dict['Metadata']['epochtimestamp'])\n",
        "            datetime_object =  datetime.fromtimestamp(cooking_date/1000)\n",
        "            #datetime_object =  datetime(*time.gmtime(cooking_date/1000.)[:6])\n",
        "            #print(time.strftime('%m/%d/%Y %H:%M:%S', time.gmtime(cooking_date/1000.)), datetime_object)\n",
        "            result_dict[file_name] = datetime_object\n",
        "\n",
        "sorted_images_dict = sorted(result_dict.items(), key=lambda x: x[1])\n",
        "print(sorted_images_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('8837b2f2-6f16-4e42-889c-5f89147ba47d.json', datetime.datetime(2020, 8, 10, 22, 40, 31, 232000)), ('e80c81d9-8c6b-4118-8ef7-ebad990e5548.json', datetime.datetime(2020, 8, 10, 22, 40, 41, 298000)), ('6fed65f6-e96a-45ff-88a7-4102af79f98c.json', datetime.datetime(2020, 8, 10, 22, 40, 51, 355000)), ('0d552bec-c6e2-4541-9410-8d7aea7c7187.json', datetime.datetime(2020, 8, 10, 22, 41, 1, 364000)), ('ce1ce25e-91f9-491e-b624-873db0e5c97d.json', datetime.datetime(2020, 8, 10, 22, 41, 11, 374000)), ('394d67e3-2fae-4d9d-8573-44d60753b0cf.json', datetime.datetime(2020, 8, 10, 22, 41, 21, 374000)), ('9851ad7c-3708-409d-aec0-b6c69a945da3.json', datetime.datetime(2020, 8, 10, 22, 41, 31, 379000)), ('9a70db2c-4ad6-4b06-82f1-5524f07a159b.json', datetime.datetime(2020, 8, 10, 22, 41, 41, 433000)), ('7f4da2ad-a097-4a76-a898-382548fa5eff.json', datetime.datetime(2020, 8, 10, 22, 41, 51, 463000)), ('6805662f-7596-4f7a-9e9d-f1dfb9aaf37b.json', datetime.datetime(2020, 8, 10, 22, 42, 1, 525000)), ('83a5c4d4-c438-4b39-9654-58360e0f8978.json', datetime.datetime(2020, 8, 10, 22, 42, 11, 541000)), ('803c2f51-a37a-499e-8c12-1dce5bbe0200.json', datetime.datetime(2020, 8, 10, 22, 42, 21, 592000)), ('31ad45c5-f195-4f56-a339-73352f1b4032.json', datetime.datetime(2020, 8, 10, 22, 42, 31, 645000)), ('e01d7eae-1b36-4f1b-9320-de197517e07e.json', datetime.datetime(2020, 8, 10, 22, 42, 41, 669000)), ('02bf64bc-5cf4-4bde-b2c0-9c5e485b97cd.json', datetime.datetime(2020, 8, 10, 22, 42, 51, 733000)), ('483c941b-5c83-4d08-be93-4c5b185f8f07.json', datetime.datetime(2020, 8, 10, 22, 43, 1, 800000)), ('739e7129-b240-4299-a866-5d304230efca.json', datetime.datetime(2020, 8, 10, 22, 43, 11, 859000)), ('444e4c08-12fd-4b0d-9a49-024ecb047865.json', datetime.datetime(2020, 8, 10, 22, 43, 21, 863000)), ('d9764960-b5dd-49be-803e-50fb2c763e38.json', datetime.datetime(2020, 8, 10, 22, 43, 31, 884000)), ('7a79a59c-ff3d-4354-820c-5c53a33e4015.json', datetime.datetime(2020, 8, 10, 22, 43, 41, 932000)), ('5835ab77-2eda-432c-a304-e5d18d3526e6.json', datetime.datetime(2020, 8, 10, 22, 47, 10, 284000)), ('6d7f6ef9-9bdb-453d-82f1-48e8bda57746.json', datetime.datetime(2020, 8, 10, 22, 47, 20, 284000)), ('ff1c0a6b-2799-4348-be5e-79a82be8ddaa.json', datetime.datetime(2020, 8, 10, 22, 47, 30, 348000)), ('aba2f4a2-0f19-45a6-9eed-ca9d571a7361.json', datetime.datetime(2020, 8, 10, 22, 47, 40, 362000)), ('56596bff-7d9d-4564-8efd-038ec7435c1f.json', datetime.datetime(2020, 8, 10, 22, 47, 50, 367000)), ('d55d22d9-9d43-4831-929d-ffb73da6a7eb.json', datetime.datetime(2020, 8, 10, 22, 48, 0, 370000)), ('53e822d9-f2fe-44be-9fd1-409d7cf455c4.json', datetime.datetime(2020, 8, 10, 22, 48, 10, 436000)), ('e6dc16d0-b458-4c46-9bce-6753ebb1b3b8.json', datetime.datetime(2020, 8, 10, 22, 48, 30, 489000)), ('e851ba5a-00e7-4445-8643-0073c9ca127f.json', datetime.datetime(2020, 8, 10, 22, 48, 40, 518000)), ('afabc69b-a457-4f68-beec-3b30ce33716d.json', datetime.datetime(2020, 8, 10, 22, 48, 50, 572000)), ('0a0708fa-2605-4c26-83f7-9f31c1594ac4.json', datetime.datetime(2020, 8, 10, 22, 49, 0, 589000)), ('15cbeb73-5430-4d23-bab2-654658931cf2.json', datetime.datetime(2020, 8, 10, 22, 49, 10, 601000)), ('4bb54351-44f1-4643-811c-d5216110d3ce.json', datetime.datetime(2020, 8, 10, 22, 49, 20, 653000)), ('e861f3e8-3c8a-4790-8b49-e7af97a9d2f1.json', datetime.datetime(2020, 8, 10, 22, 49, 30, 686000)), ('ea20327e-9bec-40ae-b692-55ff59fd8552.json', datetime.datetime(2020, 8, 10, 22, 49, 40, 745000)), ('ba1e8077-353c-4a93-912d-c1b66f53067e.json', datetime.datetime(2020, 8, 10, 22, 49, 50, 774000)), ('0ed0773a-adf5-4733-92c0-aaf6cf84b39b.json', datetime.datetime(2020, 8, 10, 22, 50, 0, 836000)), ('50f24db9-8cb8-4ef4-9658-6e93b06b6292.json', datetime.datetime(2020, 8, 10, 22, 50, 10, 851000)), ('6b25d3c5-02bc-41dc-88fa-1dc0be073212.json', datetime.datetime(2020, 8, 10, 22, 50, 20, 858000)), ('7094127a-ccea-460f-a965-3fd778f718e5.json', datetime.datetime(2020, 8, 10, 22, 50, 30, 860000)), ('c86c320c-1bea-43ca-bf9d-56f1980c8ba1.json', datetime.datetime(2020, 8, 10, 22, 50, 40, 865000)), ('bccdf73c-376b-48d5-ab8c-be0dfc1d7c01.json', datetime.datetime(2020, 8, 10, 22, 50, 50, 930000)), ('e9f5713c-20e9-4cab-9559-821098192537.json', datetime.datetime(2020, 8, 10, 22, 51, 0, 986000)), ('6af8d22c-e098-41e9-a21f-ea2dce65ebcc.json', datetime.datetime(2020, 8, 10, 22, 51, 11, 32000)), ('e0e3fd06-51df-4ced-9560-245d5b3a7dd2.json', datetime.datetime(2020, 8, 10, 22, 51, 21, 81000)), ('a1413c3c-e37d-41b6-a453-3cc67afed51b.json', datetime.datetime(2020, 8, 10, 22, 51, 31, 142000)), ('ba3931fc-75ad-44c6-8a9e-a18e01a8b124.json', datetime.datetime(2020, 8, 10, 22, 51, 41, 210000)), ('639685b6-49c7-4647-8181-1bd5f472d6b0.json', datetime.datetime(2020, 8, 10, 22, 51, 51, 210000)), ('edc0d591-0d8e-43fb-b08f-b2144c48b468.json', datetime.datetime(2020, 8, 10, 22, 52, 1, 228000)), ('7de823f8-09ae-416c-a02e-56ae4d2dfab8.json', datetime.datetime(2020, 8, 10, 22, 52, 11, 252000)), ('c37a6edb-48f5-4ceb-bae5-8b482fbf5c60.json', datetime.datetime(2020, 8, 10, 22, 52, 21, 285000)), ('ab39926f-5222-4d7e-ad17-5dc699a3b043.json', datetime.datetime(2020, 8, 10, 22, 52, 31, 285000)), ('481a922b-a4d2-480c-a7c9-f03046632d16.json', datetime.datetime(2020, 8, 10, 22, 52, 41, 306000)), ('5d54208d-3779-4969-8810-007aa39fb918.json', datetime.datetime(2020, 8, 10, 22, 52, 51, 358000)), ('99c11a2f-830f-4a0a-9005-9e67d7cddbda.json', datetime.datetime(2020, 8, 10, 22, 53, 1, 376000)), ('bd148f46-0de4-4973-8338-85b115e2d771.json', datetime.datetime(2020, 8, 10, 22, 53, 11, 441000)), ('0bfa1311-63e1-4217-be63-f62209a7f77c.json', datetime.datetime(2020, 8, 10, 22, 53, 21, 500000)), ('e838ac01-adf1-4d42-935b-97d13289a0eb.json', datetime.datetime(2020, 8, 10, 22, 53, 31, 571000)), ('3c5640de-aeaf-47a8-aca5-39e2480fb85f.json', datetime.datetime(2020, 8, 10, 22, 53, 41, 713000)), ('b0f29c35-3c2b-40ce-a807-8cb9afd54343.json', datetime.datetime(2020, 8, 10, 22, 57, 10, 392000)), ('4d138308-fe3c-4452-96e0-2b1fb1f7d6df.json', datetime.datetime(2020, 8, 10, 22, 57, 20, 394000)), ('188b6530-95ce-43f0-a2dc-5753807907fa.json', datetime.datetime(2020, 8, 10, 22, 57, 30, 397000)), ('8448c03b-3f04-4332-8076-b54eec99fe9b.json', datetime.datetime(2020, 8, 10, 22, 57, 40, 404000)), ('79fbb715-7fda-45c5-95c7-7e2e6cb87a11.json', datetime.datetime(2020, 8, 10, 22, 57, 50, 410000)), ('80352acb-fd1a-4edd-857a-b23c51857989.json', datetime.datetime(2020, 8, 10, 22, 58, 0, 454000)), ('5a21e250-fdd6-43c0-800c-0f189a4793c8.json', datetime.datetime(2020, 8, 10, 22, 58, 10, 499000)), ('54d4b73b-4539-4f6d-b364-858d9ddfd7a8.json', datetime.datetime(2020, 8, 10, 22, 58, 20, 537000)), ('591ed995-b175-4c82-8521-4cc81ac0b0aa.json', datetime.datetime(2020, 8, 10, 22, 58, 30, 571000)), ('ba709a3c-120c-4ec4-808a-cf6f92401b1b.json', datetime.datetime(2020, 8, 10, 22, 58, 40, 632000)), ('4ce383c8-ebfd-4e61-b0d1-6e2d1b1fe45d.json', datetime.datetime(2020, 8, 10, 22, 58, 50, 633000)), ('b1b10668-4547-4aa1-b2bb-78bd90433b41.json', datetime.datetime(2020, 8, 10, 22, 59, 0, 687000))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_c3yM13jCdIQ"
      },
      "source": [
        "##A generator function is designed here to provide the camera feed images to our computer vision models and oven operation logic module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCBH1B9g1CQI"
      },
      "source": [
        "def get_image_generator(sorted_images_dict, image_folder):\n",
        "  def get_next_image():\n",
        "    for img_json, timestamp in sorted_images_dict:\n",
        "      #print('elapsed time: ', elapsed_time, 'timestamp: ', str(timestamp), 'first time: ', str(first_frame_time))\n",
        "      #print(f'timestamp: {str(timestamp)}, image json : {str(img_json)}')\n",
        "      img_name = img_json.replace('.json', '.jpg')\n",
        "\n",
        "      # read in image as cv2 numpy array\n",
        "      frame = cv2.imread(os.path.join(image_folder, img_name))\n",
        "\n",
        "      # convert frame from cv2 numpy array to PIL tensor\n",
        "      img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "      tensor = pil2tensor(img, dtype=np.uint8)\n",
        "      tensor = tensor.float() / 255.\n",
        "\n",
        "      # store as fastai image\n",
        "      fastai_frame = fastai.vision.image.Image(tensor)\n",
        "      yield (img, fastai_frame, timestamp, image_folder, img_name)\n",
        "  \n",
        "  return get_next_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQMuKFMFEWZb"
      },
      "source": [
        "#This function provides our model predictions for various computer vision models such as 'pizza/non-pizza' or 'pizza doneness' model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59UFV5wzEWpi"
      },
      "source": [
        "def get_predictor(model_path, pizza_model_name):\n",
        "  predicted_categories, predicted_probabilities, frame_path_list, frame_name_list, timestamp_list = [], [], [], [], []\n",
        "  def get_image_prediction(fastai_frame, image_folder, img_name, timestamp):\n",
        "    learner = load_learner(model_path, pizza_model_name)\n",
        "\n",
        "    category, _, probs = learner.predict(fastai_frame)\n",
        "    return (str(category), list(probs), os.path.join(image_folder, img_name), img_name, timestamp)\n",
        "   \n",
        "  return get_image_prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCKhrgnYE2HQ"
      },
      "source": [
        "#We then create an incremental data frame from the camera feed. This data frame is then used to adjust our models predictions considering the uncertainty of these model outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1efY3-PN9ka"
      },
      "source": [
        "def get_prediction_dataframe(image_folder, sorted_images_dict, model_path, pizza_model_name, category_col_name, category_col_categories):\n",
        "  predicted_categories, predicted_probabilities, frame_path_list, frame_name_list, timestamp_list = [], [], [], [], []\n",
        "\n",
        "  get_image_prediction = get_predictor(model_path, pizza_model_name)\n",
        "  get_next_image = get_image_generator(sorted_images_dict, image_path_sample)\n",
        "  for img, fastai_frame, timestamp, image_folder, img_name in get_next_image():\n",
        "    category_str, probs_list, image_path, img_name, timestamp = get_image_prediction(fastai_frame, image_folder, img_name, timestamp)\n",
        "    predicted_categories, predicted_probabilities, frame_path_list, frame_name_list, timestamp_list = map(operator.add,\n",
        "                          [predicted_categories, predicted_probabilities, frame_path_list, frame_name_list, timestamp_list], \n",
        "                          [[category_str], [probs_list], [image_path], [img_name], [timestamp]])\n",
        "    df = pd.DataFrame({'timestamp': timestamp_list, 'frame_path':frame_path_list, 'frame_name':frame_name_list, 'category':predicted_categories, 'probs':predicted_probabilities})\n",
        "    df1 = pd.DataFrame(df['probs'].tolist(), index=df.index)\n",
        "    df1.columns=[category_col_name + '_Prob_' + str(i) for i in range(len(df1.columns))]\n",
        "    df[category_col_name] = df['category'].astype('category').cat.set_categories(category_col_categories)\n",
        "    yield pd.concat([df, df1], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hki_Dlm5JD-H"
      },
      "source": [
        "##Different strategies for adjustement of computer vision model predictions. Two strategies are implemented so far: 1) HMM based on discrete predictions and 2) Moving average on prediction probabilities of different categories.\n",
        "\n",
        "##In future, Klamn filter and Particle filters might produce more accurate predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmkS69gWWzvM"
      },
      "source": [
        "def normalize(x):\n",
        "    return x / x.sum()\n",
        "\n",
        "def adjust_continuous(prediction_data, column_name, column_categories):\n",
        "  prob_columns = [column for column in prediction_data.columns if column_name+'_Prob_' in column]\n",
        "  #prediction_data = prediction_data.assign(**{prob+'_adjusted':prediction_data[prob].rolling(3).mean() for prob in prob_columns})\n",
        "  prediction_data = prediction_data.assign(**{prob+'_adjusted':prediction_data[prob].rolling(3).apply(np.mean) for prob in prob_columns})\n",
        "  prob_columns_adjusted = [prob+'_adjusted' for prob in prob_columns]\n",
        "  prediction_data[column_name + '_adjusted_values'] = column_categories[np.argmax(prediction_data[prob_columns_adjusted].tail(1))]\n",
        "  return prediction_data\n",
        "\n",
        "def adjust_with_HMM(prediction_data, column_name, column_categories, start_probs, trans_matrix, emission_probs, num_states):\n",
        "  model = hmm.MultinomialHMM(n_components=num_states)\n",
        "  model.startprob_ = np.array(start_probs)\n",
        "  model.transmat_ = np.array(trans_matrix)\n",
        "  model.emissionprob_ = np.array(emission_probs)\n",
        "\n",
        "  X = np.atleast_2d(prediction_data[column_name].cat.codes).T\n",
        "  corrected_predictions = list(model.decode(X)[1])\n",
        "  prediction_data[column_name + '_adjusted'] = corrected_predictions\n",
        "  prediction_data[column_name + '_adjusted_values'] = prediction_data[column_name].cat.categories[prediction_data[column_name+'_adjusted']]\n",
        "\n",
        "def create_predictor_string(latest_predictions, category_col_name_list):\n",
        "  if latest_predictions['empty_or_full'][1].lower() == 'empty_oven':\n",
        "    return 'Empty oven'\n",
        "  if latest_predictions['pizza_nonpizza'][1].lower() == 'non-pizza':\n",
        "    return 'Not a pizza'\n",
        "  if latest_predictions['raw_or_frozen'][1].lower() == 'scratch':\n",
        "    return 'Raw pizza'\n",
        "  return latest_predictions['pizza_doneness'][1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lf3inbeSw9y"
      },
      "source": [
        "#We can create a list of models along with their corresponding HMM parameters to adjust their predictions. With this code structure, we can have arbitrary models contributing to the oven operation logic (currently summarized in 'create_predictor_string' funtion)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56WsDk50r5Mq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "601830dc-1b32-4a89-be25-35c6767b134b"
      },
      "source": [
        "model_list = ['platform_oven_empty_or_full.pkl', 'platform_pizza_classification.pkl']\n",
        "category_col_name_list = ['empty_or_full', 'pizza_doneness']\n",
        "categories_col_name_list = [('empty_oven', 'food_oven'), ('raw', 'light', 'medium', 'dark')]\n",
        "\n",
        "category_col_name_HMM_paramlist = {'empty_or_full': {'start_probs': [0.5, 0.5], \n",
        "                                                 'trans_matrix': [[0.9, 0.1], [0.1, 0.9]], \n",
        "                                                 'emission_probs': [[0.9, 0.1], [0.1, 0.9]],\n",
        "                                                 'num_states': 2\n",
        "                                                 }, \n",
        "                               'pizza_nonpizza': {'start_probs': [0.5, 0.5], \n",
        "                                                 'trans_matrix': [[0.9, 0.1], [0.1, 0.9]], \n",
        "                                                 'emission_probs': [[0.9, 0.1], [0.1, 0.9]],\n",
        "                                                 'num_states': 2\n",
        "                                                 }, \n",
        "                               'raw_or_frozen': {'start_probs': [0.5, 0.5], \n",
        "                                                 'trans_matrix': [[0.9, 0.1], [0.1, 0.9]], \n",
        "                                                 'emission_probs': [[0.9, 0.1], [0.1, 0.9]],\n",
        "                                                 'num_states': 2\n",
        "                                                 }, \n",
        "                               'pizza_doneness': {'start_probs': [0.7, 0.1, 0.1, 0.1], \n",
        "                                                 'trans_matrix': [[0.7, 0.1, 0.1, 0.1], [0.1, 0.7, 0.1, 0.1], [0.1, 0.1, 0.7, 0.1], [0.1, 0.1, 0.1, 0.7]], \n",
        "                                                 'emission_probs': [[0.7, 0.1, 0.1, 0.1], [0.1, 0.7, 0.1, 0.1], [0.1, 0.1, 0.7, 0.1], [0.1, 0.1, 0.1, 0.7]],\n",
        "                                                 'num_states': 4\n",
        "                                                 }\n",
        "                               }\n",
        "\n",
        "x = map(get_prediction_dataframe, [image_path_sample] * len(model_list), [sorted_images_dict] * len(model_list), \n",
        "        [model_path] * len(model_list), model_list, category_col_name_list, categories_col_name_list)\n",
        "z=list(x)\n",
        "\n",
        "prediction_list = np.empty((len(model_list), 0)).tolist()\n",
        "\n",
        "not_empty = True\n",
        "index = 0\n",
        "while not_empty: #and index<30:\n",
        "  df_list = []\n",
        "  latest_predictions = {}\n",
        "  index += 1\n",
        "  for i, y in enumerate(z):\n",
        "    try:\n",
        "      df = next(y)\n",
        "      if index > 3:\n",
        "        adjust_with_HMM(df, category_col_name_list[i], categories_col_name_list[i], **category_col_name_HMM_paramlist[category_col_name_list[i]])\n",
        "        #df = adjust_continuous(df, category_col_name_list[i], categories_col_name_list[i])\n",
        "        latest_prediction = list(df.tail(1)[[category_col_name_list[i], category_col_name_list[i]+'_adjusted_values']].values)\n",
        "        prediction_list[i].append(latest_prediction)\n",
        "        latest_predictions[category_col_name_list[i]] = latest_prediction[0]\n",
        "        df_list.append(df)\n",
        "    except StopIteration:\n",
        "      not_empty=False\n",
        "  if latest_predictions.keys():\n",
        "    print(f'======={create_predictor_string(latest_predictions, category_col_name_list)}========')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======light========\n",
            "=======medium========\n",
            "=======medium========\n",
            "=======medium========\n",
            "=======medium========\n",
            "=======medium========\n",
            "=======medium========\n",
            "=======medium========\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv0_VQO-u72m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}